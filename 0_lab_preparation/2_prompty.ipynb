{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Prompty\n",
    "\n",
    "Microsoft Prompty is a tool designed to help developers create, manage, and evaluate prompts for LLMs more efficiently. It works within the VSCode environment and is especially useful for refining AI interactions in GenAI pplications. <br>\n",
    "Prompty provides a standardized format (using markdown) for defining prompts, making it easier to understand, share, and debug. It allows developers to quickly prototype\n",
    "\n",
    "-   Reference: https://microsoft.github.io/promptflow/tutorials/prompty-quickstart.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: python31013jvsc74a57bd0583258b7c5128adecee42ad609cd1e06db8938097ed3afe48700fab0f5a650ee\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "module_path = \"../../0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prompt flow service...\n",
      "You can stop the prompt flow service with the following command:'\u001b[1mpf service stop\u001b[0m'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection override\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
    "\n",
    "# override configuration with AzureOpenAIModelConfiguration\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
    "    api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
    "    api_version=\"${env:AZURE_OPENAI_API_VERSION}\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0xb076f0d4898f9ec1c0b6e86e78f2eacc\n",
      "https://ai.azure.com/projecttrace/detail/0xb076f0d4898f9ec1c0b6e86e78f2eacc?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0xfba37fdd7412ed501499adf5c3e7ee38\n",
      "https://ai.azure.com/projecttrace/detail/0xfba37fdd7412ed501499adf5c3e7ee38?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0x5179977858e35aaea03a24707dbc6e66\n",
      "https://ai.azure.com/projecttrace/detail/0x5179977858e35aaea03a24707dbc6e66?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0xa7bedc4ea651012fb150f789587a9427\n",
      "https://ai.azure.com/projecttrace/detail/0xa7bedc4ea651012fb150f789587a9427?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0x9b9c57210893bc9088a1d656c4b14c44\n",
      "https://ai.azure.com/projecttrace/detail/0x9b9c57210893bc9088a1d656c4b14c44?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0x963717d266ed93a25f23cfe4a63219dd\n",
      "https://ai.azure.com/projecttrace/detail/0x963717d266ed93a25f23cfe4a63219dd?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0x0026dd41b6b0d3bd1f3dfd3c28142ffb\n",
      "https://ai.azure.com/projecttrace/detail/0x0026dd41b6b0d3bd1f3dfd3c28142ffb?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n",
      "You can view the trace detail from the following URL:\n",
      "http://127.0.0.1:23333/v1.0/ui/traces/?#collection=0_lab_preparation&uiTraceId=0x5d023ee4fe70d2fa8c56f2a875da3302\n",
      "https://ai.azure.com/projecttrace/detail/0x5d023ee4fe70d2fa8c56f2a875da3302?wsid=/subscriptions/8f94592c-747a-4bb7-ab3e-0b569993c33c/resourceGroups/rg_aistudio/providers/Microsoft.MachineLearningServices/workspaces/demo-aistudio00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tokyo is a city and does not have a capital; it is the capital of Japan.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of Japan?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'アルパインエクスプローラーテントは、プライバシーを確保するための取り外し可能な仕切りや、多数のメッシュ窓、換気用の調節可能な通気口を備えています。また、防水設計やギアロフトもあり、快適さと便利さを兼ね備えています。自然の中での快適な空間を提供する素晴らしいテントです！🌲⛺️',\n",
       " 'joke': 'ところで、テントがパーティーに行くときはいつも心配していることがあります。それは、誰が一番「張り切って」いるかということです！'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = Prompty.load(source=\"./prompty/japanese.prompty\", model=override_model)\n",
    "\n",
    "context = \"\"\"\n",
    "アルパインエクスプローラーテントには、プライバシーを確保するために取り外し可能な仕切りがあります。\n",
    "多数のメッシュ窓と換気用の調節可能な通気口、および\n",
    "防水設計が特徴です。アウトドアの必需品を収納するためのギアロフトも組み込まれています\n",
    "機器ロフトが組み込まれています。要するに、プライバシー、快適さ、\n",
    "便利さの組み合わせは、自然の中でそれを第二の家にします!\n",
    "\"\"\"\n",
    "result = f(firstName=\"Hyo\", context=context, question=\"テントについて何を知りたいですか?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: The capital of Japan is Tokyo.\n",
      "eval_result: {'score': '5', 'explanation': 'Tokyo is the capital of Japan.'}\n"
     ]
    }
   ],
   "source": [
    "flow = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "eval_flow = Prompty.load(\"./prompty/eval.prompty\", model=override_model)\n",
    "\n",
    "question = \"What is the capital of Japan?\"\n",
    "ground_truth = \"Tokyo\"\n",
    "\n",
    "result = flow(question=question)\n",
    "eval_result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "\n",
    "print(f\"result: {result}\")\n",
    "print(f\"eval_result: {eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.completion_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute 'llm.usage.prompt_tokens_details' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.completion' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n",
      "WARNING:opentelemetry.attributes:Invalid type NoneType for attribute '__computed__.cumulative_token_count.prompt' value. Expected one of ['bool', 'str', 'bytes', 'int', 'float'] or a sequence of those types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "月は地球から約384,400キロメートルの距離にあります。この距離は、地球と月の間の平均的な距離であり、重力の影響や軌道の変動によって若干の変化があります。🌌\n"
     ]
    }
   ],
   "source": [
    "LANGUAGE = \"Japanese\"\n",
    "f = Prompty.load(\"./prompty/chat.prompty\", model=override_model)\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a factual chatbot that is also sarcastic.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"384,400 kilometers\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}\n",
    "]\n",
    "question = f\"Can you speak more scientifically in {LANGUAGE}?\"\n",
    "result = f(chat_history=chat_history, question=question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
