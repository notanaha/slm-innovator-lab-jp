{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Prompty\n",
    "\n",
    "Microsoft Prompty is a tool designed to help developers create, manage, and evaluate prompts for LLMs more efficiently. It works within the VSCode environment and is especially useful for refining AI interactions in GenAI pplications. <br>\n",
    "Prompty provides a standardized format (using markdown) for defining prompts, making it easier to understand, share, and debug. It allows developers to quickly prototype\n",
    "\n",
    "-   Reference: https://microsoft.github.io/promptflow/tutorials/prompty-quickstart.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "module_path = \"../../0_lab_preparation\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "from common import check_kernel\n",
    "check_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection override\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
    "\n",
    "# override configuration with AzureOpenAIModelConfiguration\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
    "    api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
    "    api_version=\"${env:AZURE_OPENAI_API_VERSION}\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of Japan?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Prompty.load(source=\"./prompty/japanese.prompty\", model=override_model)\n",
    "\n",
    "context = \"\"\"\n",
    "アルパインエクスプローラーテントには、プライバシーを確保するために取り外し可能な仕切りがあります。\n",
    "多数のメッシュ窓と換気用の調節可能な通気口、および\n",
    "防水設計が特徴です。アウトドアの必需品を収納するためのギアロフトも組み込まれています\n",
    "機器ロフトが組み込まれています。要するに、プライバシー、快適さ、\n",
    "便利さの組み合わせは、自然の中でそれを第二の家にします!\n",
    "\"\"\"\n",
    "result = f(firstName=\"Hyo\", context=context, question=\"テントについて何を知りたいですか?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "eval_flow = Prompty.load(\"./prompty/eval.prompty\", model=override_model)\n",
    "\n",
    "question = \"What is the capital of Japan?\"\n",
    "ground_truth = \"Tokyo\"\n",
    "\n",
    "result = flow(question=question)\n",
    "eval_result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "\n",
    "print(f\"result: {result}\")\n",
    "print(f\"eval_result: {eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"Japanese\"\n",
    "f = Prompty.load(\"./prompty/chat.prompty\", model=override_model)\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a factual chatbot that is also sarcastic.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"384,400 kilometers\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}\n",
    "]\n",
    "question = f\"Can you speak more scientifically in {LANGUAGE}?\"\n",
    "result = f(chat_history=chat_history, question=question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
